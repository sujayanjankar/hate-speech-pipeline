{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "acb1e2f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, pipeline\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"tum-nlp/bert-hateXplain\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"tum-nlp/bert-hateXplain\")\n",
    "hate_classifier = pipeline(\"text-classification\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "df = pd.read_csv(\"../mdatasci/compsci-760/project/supervision_test10_threads.csv\")\n",
    "df = df.rename(columns={\"is_hate\": \"is_hate_legacy\", \"hate_label\": \"hate_label_legacy\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c667eade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_token_length(text: str) -> int:\n",
    "    try:\n",
    "        encoded_input_fixed = tokenizer(\n",
    "            text, max_length=512, truncation=True, return_tensors=\"pt\"\n",
    "        )\n",
    "        return encoded_input_fixed[\"input_ids\"].shape[1]\n",
    "    except Exception as e:\n",
    "        print(text)\n",
    "        print(e)\n",
    "        return 0\n",
    "\n",
    "\n",
    "df = df[df[\"body\"].notnull()].copy()\n",
    "df[\"token_len\"] = df[\"body\"].map(get_token_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b8abb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 918 posts.\n",
      "Shape before: (918, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying posts: 100%|██████████| 918/918 [00:04<00:00, 227.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after: (918, 12)\n",
      "hate_label\n",
      "non-toxic    811\n",
      "toxic        107\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def classify_text(text):\n",
    "    clean_text = str(text).replace(\"\\n\", \" \")\n",
    "    result = hate_classifier(clean_text)\n",
    "    return result[0][\"label\"], result[0][\"score\"]\n",
    "\n",
    "\n",
    "valid_df = df[\n",
    "    (df[\"body\"] != \"[removed]\") & (df[\"body\"] != \"[deleted]\") & (df[\"token_len\"] < 512)\n",
    "].copy()\n",
    "\n",
    "print(f\"Processing {len(valid_df)} posts.\")\n",
    "\n",
    "tqdm.pandas(desc=\"Classifying posts\")\n",
    "\n",
    "print(f\"Shape before: {valid_df.shape}\")\n",
    "\n",
    "classification_results = valid_df[\"body\"].progress_apply(classify_text)\n",
    "valid_df[\"hate_label\"] = [result[0] for result in classification_results]\n",
    "valid_df[\"hate_score\"] = [result[1] for result in classification_results]\n",
    "\n",
    "print(f\"Shape after: {valid_df.shape}\")\n",
    "print(valid_df[\"hate_label\"].value_counts())\n",
    "valid_df = valid_df.sort_values(\"hate_score\")\n",
    "valid_df.to_csv(\"supervision_test10_threads_hatexplain.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
